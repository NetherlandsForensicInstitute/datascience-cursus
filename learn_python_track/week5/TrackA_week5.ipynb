{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tutorial 5 - Pandas continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Last week, you were introduced to working with data using the Python library pandas. You've learned how to load data into Python, inspect your data, select specific rows and columns, and how to use some basic functions, to calculate i.e. the mean or minimum of any variable.\n",
    "\n",
    "This week, we continue with pandas and will cover some more advanced techniques. You will learn to create new columns in an existing dataframe, based on data values in other columns. You will also learn how to easily calculate metrics for different groups; in our XTC dataset, for example, we may be interested in calculating the mean Purity for each street sample, rather than the mean over all XTC pills.\n",
    "\n",
    "After learning these two skills, you have learned a useful chunk of what Python and pandas offer to data analysis! The last exercise is to apply all that you have learned, by creating a new notebook from scratch, and doing your first data analysis in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.0 Setting up\n",
    "As usual, we first have to import pandas and read in our dataset. We will inspect the first five rows to check that the data still looks the way we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('xtc_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.1 Adding new columns\n",
    "\n",
    "Often, you will want to add columns to your data that can be derived from other columns. For instance, maybe we do not just want to store the Diameter of each pill, but also its radius, and maybe instead of mm we want the radius to be stored in cm. First, use what you learned about selecting rows and columns in a pandas, and what you learned about simple python operators in week 1. Select the Diameter of the pill with index 4 (you can see in the output above it is 7.1 mm), and calculate the radius in cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With the skills you have, you could use a for-loop to calculate the radius in cm for each pill, then store these values in a list. This list could then be added to the dataframe like this:\n",
    "\n",
    "```python\n",
    "pills_radius = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    radius = df.loc[i, 'Diameter'] / 20\n",
    "    pills_radius.append(radius)\n",
    "\n",
    "df['Radius_cm'] = pills_radius\n",
    "```\n",
    "\n",
    "This seems like a lot of code for a relatively simple task, could it be more efficient? If you had this thought: awesome, you are starting to think like a programmer! Indeed, pandas allows us to do this kind of calculation on entire columns at once, so there is no need for the for-loop and the list.\n",
    "\n",
    "```python\n",
    "df['Radius_cm'] = df['Diameter'] / 20\n",
    "```\n",
    "\n",
    "This one line results in the same new column as the for-loop above, but it is much cleaner and also much faster. With small dataframes such as the XTC data, you won't notice the difference in processing time, but if you have large datasets, writing efficient code becomes more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise 5.1.1\n",
    "Use columns Diameter and Thickness to calculate the volume of each pill and store this as a new column. Let's assume all pills are perfectly circular, then we can calculate volume as follows: Volume = (Diameter / 2)^2 * pi * Thickness. You can use Google to find out how to use pi in Python, or simply replace it by the value 3.14.\n",
    "\n",
    "Hint: check the cheat sheet to see how to do exponentiation in Python, if you don't remember!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "We can also create new columns from string columns. In week X, you learned some methods that work on strings. For instance, `\"BLAbLa22\".lower()` will change all uppercase letters into lowercase letters, returning `\"blabla22\"`. We can also do this for whole string columns, for instance for the first column, `Street_sample_name`, which is our only string column. However, simply typing `df['Street_sample_name'].lower()` is not going to work! Try it below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Street_sample_name'].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The error message tells us that a 'Series' object has no attribute 'lower'. You don't need to know what a Series object is now, but you know that the 'lower' method only works on string variables, and although the column is filled with string values, the column itself is not a string!\n",
    "\n",
    "To use string methods on string columns in a pandas dataframe, we have to tell pandas that it first needs to access the individual strings in the column, and then apply the `.lower()` function. The correct syntax looks like this: `df['Street_sample_name'].str.lower()`. We can also save this to our dataframe with `df['Street_sample_name_lowercase'] = df['Street_sample_name'].str.lower()`\n",
    "\n",
    "The other situation in which you would need such an 'accessor' is when you have dates and/or times in your dataframe. These can be handled by pandas as special datetime variables, which make calculations on dates very easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise 5.1.2\n",
    "\n",
    "The column `Street_sample_name` has string values that start with some letters, then an underscore, and then some numbers, such as the first entry: 'LPS_1'. In week X, you learned that `\"LPS_1\".split(\"_\")` will split our string on the underscore, returning this list: `[\"LPS\", \"1\"]`.\n",
    "\n",
    "Split all the strings in the column and save both the letters and the numbers in new columns, called 'Street_name' and 'Street_number'. You can create both new columns with a single statement, using the same syntax you use for selecting multiple columns at once (`df[['column_1', 'column_2']]`. Remember that the outer square brackets are used for indexing, and the inner square brackets indicate that we are passing a list of two column names.\n",
    "\n",
    "When you try this exercise, you will likely get an error, because there is one thing we have not told you to do. It is up to you to find out how to solve it. The programmer way to tackle this is to head over to Google and search for the function you are using, and then pasting the error message. You can also copy your not-working line of code and ask ChatGPT what is wrong!\n",
    "\n",
    "After creating the two new columns, use `df.head()` to inspect the updated dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5.2 (Optional) Dealing with datetime variables\n",
    "\n",
    "In addition to the python variable types you learned about in previous weeks, pandas has some extra types (such as the DataFrame we've been working with!). Pandas can also easily deal with dates and times using the pd.datetime type. This makes calculations on dates much easier: it wouldn't be fun if you had to write your own functions for obtaining the difference between two dates, for instance. You would need to take into account months with different numbers of days, leap years, and even timezones.\n",
    "\n",
    "Dates are often stored as string values in datasets. We need to change them into datetime objects, using this function: `pd.to_datetime(df['Date'])`. If we don't specify the format of our dates, pandas will try to figure it out by itself, but this can result in incorrect dates (imagine a dataset where all the dates are '03/01/2023', is that January 3rd or March 1st?). Therefore, we usually specify the format like this: `pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")`. This tells pandas that dates are formatted with first the day as zero-padded number (`%d`), then a slash (`/`), then the month as a zero-padded number (`%m`), another slash, and lastly the year as a four-digit number (`%Y`). There are also options for non-zero-padded day or month numbers, or even months using abbreviated names (\"03-Jan-2023\"). You can find all the options in the documentation: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### (Optional) Exercise 5.2.1\n",
    "Find out the correct format of dates in the XTC dataset and transform the Date_string variable into datetime objects. Save the datetime dates in a new column called Date. Inspect the head of the dataframe to see if all looks correct. In what format does pandas show datetime objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Just like for strings, some very convenient methods exist for datetime objects. For instance, we can easily obtain the day of the week for any datetime object: `df.loc[0, 'Date'].day_name()` will return 'Tuesday', because the date in the first row of the dataframe was a Tuesday. We can also easily extract parts of the date, for instance the month number: `df.loc[0, 'Date'].month` will return '1' because this date was in January. Note that `day_name()` is called *with* parentheses, but `month` without parentheses. The difference is that `day_name()` is a function, while `month` is an attribute. You don't need to know the specifics of this difference. Other useful attributes (so called without parentheses) are `day`, `year`, `hour` and `minute`. Try them out! Our dates do not have times attached to them, so these are all set to 0:00:00 by pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### (Optional) Exercise 5.2.2\n",
    "\n",
    "Create a new column that contains the day of the week for each observation. Just like for the string columns we needed an accessor (`.str`) to apply a string method to an entire column, we now need the datetime accessor (`.dt`) to apply the datetime method to the entire column. Call the new column 'Weekday'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.3 Grouping data\n",
    "\n",
    "Last week, you learned how to do calculations on columns in a pandas dataframe, such as obtaining the mean or maximum value of a single variable. Often, we will have different groups in our data, and we would like to do these calculations for each group, separately. In our XTC dataset, perhaps we would like to know the mean weight of the pills for each 'Street_name', the column we created in the previous exercise. If we want to do this for a single group, you can combine your skills on row and column selection, and do the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only rows where the street name is equal to LPS, all columns\n",
    "df_LPS = df.loc[df['Street_name'] == 'LPS', :]\n",
    "\n",
    "# Calculate the mean of column Purity\n",
    "LPS_avg = df_LPS['Purity'].mean()\n",
    "\n",
    "print(f\"The mean purity of XTC pills collected on LPS is {LPS_avg}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "But if we wanted to calculate the mean for every street name, we'd have to do this manually many times! Luckily, pandas has built-in functions to **group** your data **by** a certain variable (or even multiple!), which allows you to do the same calculation for each group all at once. Running the code cell below will first group our dataframe by Street_name, and then calculate the mean for each group separately, for all numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('Street_name').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Just like when you calculate the mean without grouping, you can also specify for which columns you want to calculate the mean. Of course, we can also still calculate other metrics, such as the minimum, maximum, sum, or count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the mean of a single column\n",
    "df.groupby('Street_name')['Purity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the count of multiple columns (a row counts if it is not empty for that variable)\n",
    "df.groupby('Street_name')[['Purity', 'Weight', 'Diameter']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise 5.3.1\n",
    "\n",
    "Our dataset contains information on which dates the XTC samples were collected. In exercises 5.2.1 and 5.2.2 you added a column to the dataframe with the day of the week for each row. Use `.groupby` and the appropriate aggregation function to find out on which day of the week most samples were collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you did not do exercises 5.2.1 and 5.2.2, run this code cell first\n",
    "df['Date'] = pd.to_datetime(df['Date_string'], format=\"%d-%m-%Y\")\n",
    "df['Weekday'] = df['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise 5.3.2\n",
    "\n",
    "We don't have to limit ourselves to just one grouping variable! Maybe we are interested in finding out the number of samples collected on each weekday, separately for each Street_name. You can do this by passing a list to `.groupby()` instead of a single string. When you group by multiple variables, pandas will return something called a 'multi-index dataframe'. These can be a bit tricky to work with, and selecting rows and columns becomes harder. It is often useful to add `.reset_index()` at the end (right after `.sum()` or whichever aggregation function you are calculating). This transforms the dataframe back to a 'flat' dataframe on which you can select rows and columns the way you learned last week.\n",
    "\n",
    "Using `.groupby()`, obtain the number of samples collected on each weekday, for each Street_name. Your resulting dataframe should not be multi-index, and should have three columns: Street_name, Weekday and Count. You will have to rename one column to Count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.4 (Optional) Advanced aggregating\n",
    "\n",
    "So far, we have seen how to calculate one aggregation function for one or multiple columns, with or without grouping our data. There is also a trick to calculate different aggregations per column! The following code calculates the mean of column 'Weight', the maximum of column 'Purity' and the count of column 'Street_sample_name', and saves this as `df_summary`. We then rename the columns to better describe their values. You can also do this with a chained statement without saving the aggregated dataframe first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_summary = df.agg({'Weight': 'mean',\n",
    "                     'Purity': 'max',\n",
    "                     'Street_sample_name': 'count'})\n",
    "\n",
    "df_summary = df_summary.rename(index={'Weight': 'mean_weight',\n",
    "                                      'Purity': 'max_purity',\n",
    "                                      'Street_sample_name': 'count'})\n",
    "\n",
    "# Or chained (by using parentheses, we can split the code over multiple lines freely):\n",
    "df_summary = (\n",
    "        df.agg({'Weight': 'mean',\n",
    "                'Purity': 'max',\n",
    "                'Street_sample_name': 'count'})\n",
    "        .rename(index={'Weight': 'mean_weight',\n",
    "                       'Purity': 'max_purity',\n",
    "                       'Street_sample_name': 'count'})\n",
    ")\n",
    "\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You may wonder what we are passing as argument to `.agg()` and `.rename()`, with the curly brackets {}. This type of variable is called a dictionary, and you can learn more about them in the FutureCoder course. Note that `.rename()` can rename either row indices or columns. In this case, the aggregated dataframe has put what were originally our columns (Weight, Purity and Street_sample_name) on the rows instead. Therefore, when we rename them, we have to tell `.rename()` that we want to rename the **index**, not the **columns**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### (Optional) Exercise 5.4.1\n",
    "\n",
    "For each day of the week, calculate the following: number of samples collected, maximum diameter, and total volume of the collected pills. Make sure to rename your variables appropriately. Before renaming, inspect your dataframe to see if you need to rename the index or the columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.5 Visualisations by group\n",
    "\n",
    "Last week you learned how to make some visualisations in python using the matplotlib library. Today we will extend this skill by showing you how to plot multiple groups in one graph, and create side-by-side graphs.\n",
    "\n",
    "First, let's recreate the scatterplot with variables Diameter and Weight from last week, but this time, we will also use color to show the Street_name on which the sample was collected. Unfortunately, the `plt.scatter()` function can only make simple scatterplots, and if we want to give colors per category, we need to use the more general function `plt.plot()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, group your dataframe by the variable you want to use for color\n",
    "groups = df.groupby('Street_name')\n",
    "\n",
    "# Second, we need to instantiate an empty plot to which we can add the data\n",
    "# for each group\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Third, we loop over the grouped dataframe and plot each group in the same graph\n",
    "for name, group in groups:\n",
    "    # name is now the current value of Street_name (e.g., LPS),\n",
    "    # while group holds the dataframe with its observations\n",
    "    ax.plot(group['Diameter'], group['Weight'], marker='o', linestyle='', label=name)\n",
    "\n",
    "# Add a legend and show the plot!\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "So what did we do here exactly?\n",
    "\n",
    "`fig, ax = plt.subplots()` creates a new figure (`fig`), and one 'axis' (`ax`). This is a useful way to create plots, because it is very flexible and allows you to create side-by-side plots too. We did not pass any arguments to `plt.subplots()`, so now we are just getting one axis within our figure, and we will plot all groups on the same axis so that it becomes one graph.\n",
    "\n",
    "In `ax.plot()`, we now give some more arguments. The first two are our x and y values to plot. `marker='o'` specifies that each datapoint should be represented by a circle, `linestyle=''` specifies that lines should not be drawn between data points. `label=name` sets the label for each group to be equal to `name`, which is the value of Street_name for the group we are currently plotting. This is needed in order to add a legend to the figure later on. Check out the documentation of matplotlib for more marker and linestyle options, as well as more advanced formatting!\n",
    "\n",
    "With `ax.legend()`, we add a legend to our plot showing which color corresponds to which Street_name. You can pass more arguments to this function, for instance to specify the location of the legend (when empty, matplotlib will try to find a suitable spot for the legend). Again, check the documentation for all possible options!\n",
    "\n",
    "---\n",
    "\n",
    "In the case of this scatterplot, it makes sense to have all categories together in one graph. However, if we would like to recreate the histogram of pill weights for each group, it would make more sense to show them in separate subplots. We now have to specify how many subplots we want to have to `plt.subplots()`. We have four different values for Street_name, so a figure with 2x2 subplots seems like a good choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Great, we now have four empty subplots! Before, we would use `ax.plot()` to add data to our axis, as we had only one axis. Now, we have 4 axes! We use indexing to specify which axis we want to plot in. `ax[0, 0].plot()` adds data to the top left axis (row index is 0, column index is 0); `ax[1, 0].plot()` adds data to the bottom left axis (row index is 1, column index is 0); etcetera.\n",
    "\n",
    "*Bonus: what kind of indexing do you need if you create a figure with subplots in only one dimension, i.e., using only one row or column? Try it out!*\n",
    "\n",
    "There are more elegant ways to specify which axis you want to plot each group in, but the code below is understandable for pandas-beginners and works fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Street_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = df.groupby('Street_name')\n",
    "\n",
    "# The parameters sharex and sharey control whether the subplots should\n",
    "# all have the same x and y axes. By default, both are false\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True)\n",
    "\n",
    "for name, group in groups:\n",
    "    if name == 'LPS':\n",
    "        current_ax = ax[0, 0]\n",
    "    elif name == 'UNIL':\n",
    "        current_ax = ax[0, 1]\n",
    "    elif name == 'NFI':\n",
    "        current_ax = ax[1, 0]\n",
    "    else:\n",
    "        current_ax = ax[1, 1]\n",
    "    current_ax.hist(group['Weight'])\n",
    "    # Add the street name as title for the current axis\n",
    "    current_ax.set_title(f\"Street {name}\")\n",
    "    # Add labels (note that these are different functions than when we are\n",
    "    # creating a single plot without plt.subplots()!\n",
    "    current_ax.set_xlabel(\"Weight\")\n",
    "    current_ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# This ensures that our titles and axis labels do not overlap. Try running this\n",
    "# cell without it and see the difference!\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the result!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise 5.5.1\n",
    "\n",
    "We have shown you how to make the same plot for different groups in different subplots. However, we can also use subplots to show different plots! Create a figure with two subplots, one showing a histogram of Purity, and the other showing a scatterplot for Diameter and Thickness. Make sure to add labels and/or titles to your figure! You can also play around with different colors and/or marker styles.\n",
    "\n",
    "*Hint: you don't have to use groupby or a for loop to do this!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.6 Putting it all together\n",
    "\n",
    "It's time for the final exercise: combine everything you've learned in your very first data analysis with python!\n",
    "\n",
    "1. Select a suitable data file that you have, or download a dataset from the NFI Github: https://github.com/NetherlandsForensicInstitute\n",
    "2. Create a new notebook, import the required libraries and load your data\n",
    "3. Inspect your data; make sure variables are of the correct type\n",
    "4. Check for missing data, and handle these appropriately\n",
    "5. Explore your data, make some plots to show variable distributions and/or correlations\n",
    "6. Do a grouped analysis that makes sense for your variables\n",
    "\n",
    "Make sure to add markdown cells in between your code cells with explanations of what you are doing and why. Someone should be able to understand your analysis from the notebook alone! When you are finished with the analysis, go through the notebook once more to clean up unused code and make sure everything runs the way it is supposed to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.7 Now what?\n",
    "\n",
    "Congratulations, you have finished this introductory course to Data Science in python! If you want to continue learning about data science and pandas, there is another set of notebooks that guide you through the whole data science pipeline. You will learn about splitting data, training various models, selecting the best model, and validating it! We hope you enjoyed getting to know python and pandas, and that your data science journey is just beginning.\n",
    "If you feel like you want to learn even more, we recommend the free book [_Python for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter_](https://wesmckinney.com/book/), written by Wes McKinney, the creator of Pandas.\n",
    "\n",
    "Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
